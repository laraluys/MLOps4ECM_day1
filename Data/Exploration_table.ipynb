{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63bd97ab",
   "metadata": {},
   "source": [
    "# Tabular data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfab9ee",
   "metadata": {},
   "source": [
    "## Imports needed for data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ec668e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398ef079",
   "metadata": {},
   "source": [
    "## Data importation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702bb61c",
   "metadata": {},
   "source": [
    "For tabular data we are using a water potability dataset which can be found on [Kaggle](https://www.kaggle.com/datasets/adityakadiwal/water-potability). This dataset is located in our directory under \"datasets/water_potability\" and has a csv file format.</br></br>\n",
    "Before we can do anything with our dataset we need to load it into python. The easiest way to read and work with tabular data is to use the Pandas library. </br>\n",
    "To read data from a csv file we use the following command: \n",
    "\n",
    "<code> data = pd.read_csv(\"pathname/to/dataset.csv\", delimiter=\",\" , index_col=None) </code>\n",
    "\n",
    "This code creates a pandas.DataFrame type. This type has a number of methods to obtain some basic insights into the data: (1) <code>.head(n)</code> to see the first n rows in the dataframe, (2) <code>.info()</code> to see general information about the columns and dataframe, and (3) <code>.describe()</code> to see basic statistics for each feature. Use these methods to explore the dataframe and answer the following questions:\n",
    "\n",
    "What is the number of rows in the dataframe: \n",
    "\n",
    "What is the number of columns in the dataframe: \n",
    "\n",
    "What is the number of features in the data: \n",
    "\n",
    "What is the memory usage of the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19951870",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4a6714",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6664875",
   "metadata": {},
   "source": [
    "## Explore the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e335be7",
   "metadata": {},
   "source": [
    "### Null values\n",
    "\n",
    "An important aspect of your dataset is that it is \"clean\". This means that there are no None, Null, NaN or other values given in the dataset.</br>\n",
    "Using Pandas it is easy to find the exact amount of none-values using the following command:\n",
    "\n",
    "<code>number_of_nan_in_column = dataframe[\"column_name\"].isnull().sum() </code>\n",
    "\n",
    "Do this for all columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91b3970",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3de67688",
   "metadata": {},
   "source": [
    "### Feature distribution\n",
    "Sometimes the different features/variables in your dataset can have different ranges. This seams fine at first glance but can cause problems in certain algorithms like Gradient Descent where variables with larger values can have a larger affect on your gradients than variables with smaller values. Therefore it is a good idea to create histograms of your different variables to know which values have which ranges. It can also give you more information about the different distributions of the parameters, this can be especially interesting with the labels where an underrepresentation of a certain class could cause a problem in the classification. </br>\n",
    "Use the following command to show the different histograms of the columns in your pandas dataframe:\n",
    "\n",
    "<code>dataframe.hist(figsize=[width_in_inch, height_in_inch])</code>\n",
    "\n",
    "Look at the histograms and look at their distributions. Are there any features that could cause a problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d866b92d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4bee602",
   "metadata": {},
   "source": [
    "### Correlations\n",
    "When working with large datasets there might be too many features making training and inference on your dataset very slow. In those situations there is a higher chance that some features are not necessary. This can be checked by creating a correlation matrix between the different features. There are several different ways to calculate this like the \"spearman\" or \"pearson\" correlation values. Both show the correlation with values between -1 and 1 where -1 means a negative correltation and 1 a positive correlation. With Pandas, these correlation matrices can be calculated as follows:\n",
    "\n",
    "<code>dataframe.corr(\"spearman\")</code>\n",
    "\n",
    "</br>\n",
    "To make the matrix more readable you have several options. The first one is to use matplotlib:\n",
    "\n",
    "<code>plt.matshow(matrix)</br>\n",
    "plt.colorbar()</br>\n",
    "plt.show()</br>\n",
    "</code>\n",
    "\n",
    "</br>\n",
    "A second option is to use seaborn. There you create a subplot using matplotlib and then create a heatmap using seaborn:\n",
    "\n",
    "<code>\n",
    "f, ax = plt.subplots()</br>\n",
    "sns.heatmap(matrix, vmin=minimum, vmax=maximum, ax=ax)\n",
    "</code>\n",
    "\n",
    "One of the two Hardness columns is the real Hardness, the other is just a combination of two other columns in the dataset. Which one is the real one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2eccde4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3feb05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea67fb15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
